{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8bd4baf8",
      "metadata": {
        "id": "8bd4baf8"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from bs4 import BeautifulSoup\n",
        "import urllib.parse\n",
        "from urllib.parse import urlparse\n",
        "from collections import defaultdict\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "898593ef",
      "metadata": {
        "id": "898593ef"
      },
      "outputs": [],
      "source": [
        "# Define a function to extract the original URL from Facebook redirect URLs\n",
        "def extract_original_url(fb_url):\n",
        "    parsed_url = urllib.parse.urlparse(fb_url)\n",
        "    query_params = urllib.parse.parse_qs(parsed_url.query)\n",
        "    return query_params.get('u', [None])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3fed385f",
      "metadata": {
        "id": "3fed385f"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# URL a fájlhoz\n",
        "url = 'https://raw.githubusercontent.com/RickGCartmanland/Pocket/main/ril_export.html'\n",
        "\n",
        "# HTTP kérés a fájl letöltéséhez\n",
        "response = requests.get(url)\n",
        "\n",
        "# Ellenőrizze, hogy a kérés sikeres volt-e\n",
        "if response.status_code == 200:\n",
        "    html_content = response.text\n",
        "\n",
        "    # HTML fájl elemzése BeautifulSoup segítségével\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "    # Itt folytathatja a fájl feldolgozását...\n",
        "    # Például: URL-ek kinyerése, adatok csoportosítása, stb.\n",
        "else:\n",
        "    print(\"Nem sikerült letölteni a fájlt. Hiba kód:\", response.status_code)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e63e8b5d",
      "metadata": {
        "id": "e63e8b5d"
      },
      "outputs": [],
      "source": [
        "# Extract all URLs and group them by domain\n",
        "all_domain_urls = defaultdict(list)\n",
        "for link in soup.find_all('a', href=True):\n",
        "    url = link.get('href')\n",
        "    domain = urlparse(url).netloc\n",
        "    all_domain_urls[domain].append(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d92b5f86",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d92b5f86",
        "outputId": "d6f3197d-306b-48c6-9b4b-07e21d92f143"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'phys.org': 9,\n",
              " 'bit.ly': 5,\n",
              " 'github.com': 5,\n",
              " 'www.genengnews.com': 4,\n",
              " 'www.sciencealert.com': 3,\n",
              " 'www.technologyreview.com': 3,\n",
              " 'medicalxpress.com': 3,\n",
              " 'www.technologynetworks.com': 3,\n",
              " 'arxiv.org': 3,\n",
              " 'go.nature.com': 2,\n",
              " 'www.iflscience.com': 2,\n",
              " 'index.hu': 2,\n",
              " 'www.analyticsvidhya.com': 2,\n",
              " 'towardsdatascience.com': 2,\n",
              " 'scitechdaily.com': 1,\n",
              " 'hirlevel.egov.hu': 1,\n",
              " 'techxplore.com': 1,\n",
              " 'smosa.com': 1,\n",
              " 'madewithml.com': 1,\n",
              " 'www.youtube.com': 1,\n",
              " 'buff.ly': 1,\n",
              " 'medium.com': 1,\n",
              " 'lnkd.in': 1,\n",
              " 'mathislab.org': 1,\n",
              " 'www.linkedin.com': 1,\n",
              " 'www.theguardian.com': 1,\n",
              " 'trib.al': 1,\n",
              " 'www.diagnosticimaging.com': 1,\n",
              " '444.hu': 1,\n",
              " 'www.extremetech.com': 1,\n",
              " 'cbirt.net': 1,\n",
              " 'www.labroots.com': 1,\n",
              " 'logout.hu': 1,\n",
              " 'tomasp.net': 1,\n",
              " 'simonjf.com': 1,\n",
              " 'www.neuroscientistnews.com': 1,\n",
              " 'vilagterkep.atlatszo.hu': 1,\n",
              " 'nepszava.us': 1,\n",
              " 'advances.sciencemag.org': 1,\n",
              " 'mubaris.com': 1,\n",
              " 'www.atv.hu': 1,\n",
              " 'www.google.com': 1,\n",
              " 'epiteszforum.hu': 1,\n",
              " 'www.telerik.com': 1,\n",
              " 'm.facebook.com': 1,\n",
              " 'www.eltereader.hu': 1,\n",
              " 'docs.microsoft.com': 1,\n",
              " '24.hu': 1,\n",
              " 'www.huffingtonpost.com': 1,\n",
              " 'www.researchgate.net': 1,\n",
              " 'm.phys.org': 1,\n",
              " 'www.nature.com': 1,\n",
              " 'www.academia.edu': 1,\n",
              " 'cdn.openai.com': 1,\n",
              " 'kasvith.me': 1,\n",
              " 'sourceforge.net': 1,\n",
              " 'newsroom.gehealthcare.com': 1,\n",
              " 'drive.google.com': 1,\n",
              " 'www.nytimes.com': 1,\n",
              " 'fsharpforfunandprofit.com': 1,\n",
              " 'blog.jldc.me': 1,\n",
              " 'www.chessable.com': 1,\n",
              " 'www.drdobbs.com': 1,\n",
              " 'www.wired.com': 1,\n",
              " 'houseofbots.com': 1,\n",
              " 'martinfowler.com': 1}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Resolve Facebook URLs and count URLs by domain\n",
        "original_domain_counts = defaultdict(int)\n",
        "for domain, urls in all_domain_urls.items():\n",
        "    if domain in ['l.facebook.com', 'lm.facebook.com']:\n",
        "        for fb_url in urls:\n",
        "            original_url = extract_original_url(fb_url)\n",
        "            if original_url:\n",
        "                original_domain = urlparse(original_url).netloc\n",
        "                original_domain_counts[original_domain] += 1\n",
        "    else:\n",
        "        original_domain_counts[domain] += len(urls)\n",
        "\n",
        "# Display the sorted count of URLs by domain\n",
        "sorted_original_domain_counts = dict(sorted(original_domain_counts.items(), key=lambda item: item[1], reverse=True))\n",
        "sorted_original_domain_counts"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
