{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd4baf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "from urllib.parse import urlparse\n",
    "from collections import defaultdict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898593ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract the original URL from Facebook redirect URLs\n",
    "def extract_original_url(fb_url):\n",
    "    parsed_url = urllib.parse.urlparse(fb_url)\n",
    "    query_params = urllib.parse.parse_qs(parsed_url.query)\n",
    "    return query_params.get('u', [None])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fed385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with the path to your HTML file\n",
    "html_file_path = 'path/to/ril_export.html'\n",
    "\n",
    "# Read and parse the HTML file\n",
    "with open(html_file_path, 'r', encoding='utf-8') as file:\n",
    "    soup = BeautifulSoup(file, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63e8b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all URLs and group them by domain\n",
    "all_domain_urls = defaultdict(list)\n",
    "for link in soup.find_all('a', href=True):\n",
    "    url = link.get('href')\n",
    "    domain = urlparse(url).netloc\n",
    "    all_domain_urls[domain].append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92b5f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolve Facebook URLs and count URLs by domain\n",
    "original_domain_counts = defaultdict(int)\n",
    "for domain, urls in all_domain_urls.items():\n",
    "    if domain in ['l.facebook.com', 'lm.facebook.com']:\n",
    "        for fb_url in urls:\n",
    "            original_url = extract_original_url(fb_url)\n",
    "            if original_url:\n",
    "                original_domain = urlparse(original_url).netloc\n",
    "                original_domain_counts[original_domain] += 1\n",
    "    else:\n",
    "        original_domain_counts[domain] += len(urls)\n",
    "\n",
    "# Display the sorted count of URLs by domain\n",
    "sorted_original_domain_counts = dict(sorted(original_domain_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "sorted_original_domain_counts"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
